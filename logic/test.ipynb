{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytesseract\n",
      "Version: 0.3.10\n",
      "Summary: Python-tesseract is a python wrapper for Google's Tesseract-OCR\n",
      "Home-page: https://github.com/madmaze/pytesseract\n",
      "Author: Samuel Hoffstaetter\n",
      "Author-email: samuel@hoffstaetter.com\n",
      "License: Apache License 2.0\n",
      "Location: E:\\practice\\Image_mcq\\Lib\\site-packages\n",
      "Requires: packaging, Pillow\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TESSDATA_PREFIX'] = r'C:/Users/mayank.vanik/AppData/Local/Programs/Tesseract-OCR/tessdata'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Users/mayank.vanik/AppData/Local/Programs/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Question: Which sorting algorithm is implemented in the following\n",
      "code snippet?\n",
      "Python o\n",
      "def bubble_sort(arr):\n",
      "n = len(arr)\n",
      "for 4 in range(n):\n",
      "for j in range(@, n - i - 4):\n",
      "if arr[j] > arr[j + 4]:\n",
      "arr[j], arr[j + 1] = arr[j + 4], arr[j]\n",
      "numbers = [5, 2, 9, 1, 5, 6]\n",
      "bubble_sort (numbers)\n",
      "print (numbers)\n",
      "Al-generated code, Review and use carefully. More info on FAQ\n",
      "A) Quick sort B) Merge sort C) Bubble sort D) Selection sort\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "img = Image.open('E:/practice/Image_mcq/02.jpg.png')\n",
    "\n",
    "# Perform OCR using Tesseract\n",
    "text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Users/mayank.vanik/AppData/Local/Programs/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-groq\n",
      "Version: 0.1.3\n",
      "Summary: An integration package connecting Groq and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: E:\\practice\\Image_mcq\\Lib\\site-packages\n",
      "Requires: groq, langchain-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "from pprint import pprint\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "GROQ_LLM = ChatGroq(\n",
    "            model=\"llama3-70b-8192\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is a 30-word poem for your angel:\\n\\n\"My angel, you shine so bright, a beacon in the dark of night. Your love illuminates my soul, a radiant heart that makes me whole.\"', response_metadata={'token_usage': {'completion_time': 0.148, 'completion_tokens': 42, 'prompt_time': 0.056, 'prompt_tokens': 18, 'queue_time': None, 'total_time': 0.204, 'total_tokens': 60}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_abd29e8833', 'finish_reason': 'stop', 'logprobs': None}, id='run-7bead32d-d3c5-4ab3-9171-7613223f6128-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GROQ_LLM.invoke('write 30 word poem for my angel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (0.1.56)\n",
      "Collecting numpy<2,>=1\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in e:\\practice\\image_mcq\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\practice\\image_mcq\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\practice\\image_mcq\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in e:\\practice\\image_mcq\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\practice\\image_mcq\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\practice\\image_mcq\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\practice\\image_mcq\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\practice\\image_mcq\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\practice\\image_mcq\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\practice\\image_mcq\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, attrs, yarl, typing-inspect, SQLAlchemy, aiosignal, dataclasses-json, aiohttp, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 dataclasses-json-0.6.5 frozenlist-1.4.1 greenlet-3.0.3 langchain-0.1.19 langchain-community-0.0.38 langchain-text-splitters-0.0.1 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize EMAIL\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a Email Categorizer Agent You are a master at understanding what a customer wants when they write an email and are able to categorize it in a useful way\n",
    "\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Conduct a comprehensive analysis of the email provided and categorize into one of the following categories:\n",
    "        price_equiry - used when someone is asking for information about pricing \\\n",
    "        customer_complaint - used when someone is complaining about something \\\n",
    "        product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
    "        customer_feedback - used when someone is giving feedback about a product \\\n",
    "        off_topic when it doesnt relate to any other category \\\n",
    "\n",
    "\n",
    "            Output a single cetgory only from the types ('price_equiry', 'customer_complaint', 'product_enquiry', 'customer_feedback', 'off_topic') \\\n",
    "            eg:\n",
    "            'price_enquiry' \\\n",
    "\n",
    "    EMAIL CONTENT:\\n\\n {initial_email} \\n\\n\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"initial_email\"],\n",
    ")\n",
    "\n",
    "email_category_generator = prompt | GROQ_LLM | StrOutputParser()\n",
    "\n",
    "EMAIL = \"\"\"HI there, \\n\n",
    "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
    "\n",
    "I really appreaciate what your staff did\n",
    "\n",
    "Thanks,\n",
    "Paul\n",
    "\"\"\"\n",
    "\n",
    "result = email_category_generator.invoke({\"initial_email\": EMAIL})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct answer is C) Bubble sort.\n",
      "\n",
      "The code snippet provided is an implementation of the Bubble sort algorithm, which repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate( template=\"\"\"Choose the correct option for the question. If the question is code-related,\n",
    "                         ensure correct code indentation and select the right option from the given choices.\n",
    "\n",
    "Question: \\n\\n {initial_Question} \\n\\n \"\"\", input_variables=[\"initial_Question\"], )\n",
    "\n",
    "mail_category_generator = prompt | GROQ_LLM | StrOutputParser()\n",
    "\n",
    "EMAIL = \"\"\"4. Question: Which sorting algorithm is implemented in the following\n",
    "code snippet?\n",
    "Python o\n",
    "def bubble_sort(arr):\n",
    "n = len(arr)\n",
    "for 4 in range(n):\n",
    "for j in range(@, n - i - 4):\n",
    "if arr[j] > arr[j + 4]:\n",
    "arr[j], arr[j + 1] = arr[j + 4], arr[j]\n",
    "numbers = [5, 2, 9, 1, 5, 6]\n",
    "bubble_sort (numbers)\n",
    "print (numbers)\n",
    "Al-generated code, Review and use carefully. More info on FAQ\n",
    "A) Quick sort B) Merge sort C) Bubble sort D) Selection sort\n",
    "\"\"\"\n",
    "result = mail_category_generator.invoke({\"initial_Question\": EMAIL})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_mcq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
